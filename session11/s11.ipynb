{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ping-Mel/ERV-V2-Assignments/blob/main/session11/s11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUALKIqUQzaR",
        "outputId": "972f4897-4ba3-4cf4-eef7-cd8671879ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ERA-V2-Architecture==0.1.3 in /usr/local/lib/python3.10/dist-packages (0.1.3)\n"
          ]
        }
      ],
      "source": [
        "pip install ERA-V2-Architecture==0.1.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akVIWUfTQzaW",
        "outputId": "2740a3b3-fe99-4a4a-8d78-0a72653b71af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "from ERA_V2_Architecture.model import ResNet\n",
        "from ERA_V2_Architecture.model import BasicBlock\n",
        "from ERA_V2_Architecture.model import Models\n",
        "\n",
        "!pip install torchsummary\n",
        "from __future__ import print_function\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Now you can use the classes and functions defined in models.py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_blocks = [2, 2, 2, 2]  # Typical configuration for ResNet-18\n",
        "num_classes = 10  # Adjust based on your specific dataset\n",
        "\n",
        "# Check for CUDA availability\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "model = ResNet(BasicBlock, num_blocks, num_classes=num_classes).to(device)\n"
      ],
      "metadata": {
        "id": "_IoU0tlGqFWb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from torchsummary import summary\n",
        " summary(model, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "id": "avv8hF10qibP",
        "outputId": "47e52de4-1d0b-4204-e3c5-8b71f0446d3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
            "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.25\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 53.89\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10Albumentations:\n",
        "    def __init__(self, root='./data', train=True, transform=None):\n",
        "        self.data = datasets.CIFAR10(root, train=train, download=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx]\n",
        "        if self.transform:\n",
        "            # Convert PIL image to numpy array\n",
        "            image_np = np.array(image)\n",
        "            # Apply the transformations\n",
        "            augmented = self.transform(image=image_np)\n",
        "            image = augmented['image']\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "TVfU18AQwbBb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_dataset = [0.4914 * 255, 0.4822 * 255, 0.4465 * 255]\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "                                      transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                       ])\n",
        "\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                       ])"
      ],
      "metadata": {
        "id": "PTtrzAHMwcK2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train = datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n",
        "train = CIFAR10Albumentations(root='./data', train=True, transform=train_transforms)\n",
        "test = datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)"
      ],
      "metadata": {
        "id": "Nwp2GF-JwgFU",
        "outputId": "d63b7965-384b-4d24-b5f5-a4b851eeeede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_misclasses(failed_samples, title):\n",
        "  CIFAR10_CLS = {\n",
        "    0: 'Airplane',\n",
        "    1: 'Automobile',\n",
        "    2: 'Bird',\n",
        "    3: 'Cat',\n",
        "    4: 'Deer',\n",
        "    5: 'Dog',\n",
        "    6: 'Frog',\n",
        "    7: 'Horse',\n",
        "    8: 'Ship',\n",
        "    9: 'Truck'\n",
        "  }\n",
        "\n",
        "  fig, axs = plt.subplots(5,2,figsize=(8,10))\n",
        "  fig.suptitle(title, fontsize=16)\n",
        "\n",
        "  for idx, (img, actual, pred) in enumerate(failed_samples[:10]):\n",
        "      ax = axs[idx // 2, idx % 2]\n",
        "      img = img.cpu().numpy().transpose((1, 2, 0))  # Convert to numpy and fix channel ordering\n",
        "      img = (img - img.min()) / (img.max() - img.min())  # Normalize to [0,1]\n",
        "      ax.imshow(img, interpolation='none')\n",
        "      ax.set_title(f'Actual: {CIFAR10_CLS[actual]}, Pred: {CIFAR10_CLS[pred]}')\n",
        "      ax.axis('off')\n",
        "\n",
        "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nTxrIsO1wjKQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=256, num_workers=2, pin_memory=True) if cuda else dict(shuffle=True, batch_size=128)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "metadata": {
        "id": "F4-0mlbnwmu7",
        "outputId": "ba67c81b-94b6-412b-c6cb-daafe7e40df1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import relu\n",
        "\n",
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, model, layer_name):\n",
        "        self.model = model\n",
        "        self.layer_name = layer_name\n",
        "        self.gradient = None\n",
        "        self.activation = None\n",
        "        self.hook_layers()\n",
        "\n",
        "    def hook_layers(self):\n",
        "        def get_activation_hook(module, input, output):\n",
        "            self.activation = output\n",
        "\n",
        "        def get_gradient_hook(module, grad_in, grad_out):\n",
        "            self.gradient = grad_out[0]\n",
        "\n",
        "        for name, module in self.model.named_modules():\n",
        "            if name == self.layer_name:\n",
        "                module.register_forward_hook(get_activation_hook)\n",
        "                module.register_backward_hook(get_gradient_hook)\n",
        "\n",
        "    def visualize(self, input_image, class_idx):\n",
        "        # Forward pass\n",
        "        output = self.model(input_image)\n",
        "        class_output = output[:, class_idx]\n",
        "\n",
        "        # Backward pass\n",
        "        self.model.zero_grad()\n",
        "        class_output.backward(retain_graph=True)\n",
        "\n",
        "        # Generate Grad-CAM heatmap\n",
        "        pooled_gradients = torch.mean(self.gradient, dim=[0, 2, 3])\n",
        "        for i in range(self.activation.shape[1]):\n",
        "            self.activation[:, i, :, :] *= pooled_gradients[i]\n",
        "\n",
        "        heatmap = torch.mean(self.activation, dim=1).squeeze().cpu()\n",
        "        heatmap = relu(heatmap)\n",
        "        heatmap /= torch.max(heatmap)\n",
        "\n",
        "        # Render heatmap\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "        img = input_image.cpu().data.numpy()[0].transpose((1, 2, 0))\n",
        "        img = (img - img.min()) / (img.max() - img.min())\n",
        "        heatmap = heatmap.numpy()\n",
        "        heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "        superimposed_img = heatmap * 0.4 + img * 255\n",
        "        plt.imshow(superimposed_img / 255)\n",
        "        plt.show()\n",
        "\n",
        "    def generate_heatmap(self, input_image, class_idx):\n",
        "        self.model.eval()\n",
        "        output = self.model(input_image)\n",
        "        output.requires_grad_(True)\n",
        "        class_output = output[:, class_idx]\n",
        "        self.model.zero_grad()\n",
        "        class_output.backward(retain_graph=True)\n",
        "\n",
        "        pooled_gradients = torch.mean(self.gradient, dim=[0, 2, 3])\n",
        "        for i in range(self.activation.shape[1]):\n",
        "            self.activation[:, i, :, :] *= pooled_gradients[i]\n",
        "\n",
        "        heatmap = torch.mean(self.activation, dim=1).squeeze()\n",
        "        heatmap = F.relu(heatmap)\n",
        "        heatmap /= torch.max(heatmap)\n",
        "        heatmap = heatmap.cpu().numpy()\n",
        "        heatmap = cv2.resize(heatmap, (input_image.shape[2], input_image.shape[3]))  # Resize to the input size\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "        return heatmap\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# grad_cam = GradCAM(model, 'layer4')\n",
        "# images, labels = iter(testloader).next()\n",
        "# grad_cam.visualize(images, labels.numpy()[0])\n"
      ],
      "metadata": {
        "id": "cbRT1FQu1BRx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "failed_samples = []\n",
        "grad_cam_samples = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}%')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            # New code block to check for incorrect predictions\n",
        "            matches = pred.eq(target.view_as(pred))\n",
        "            for idx, match in enumerate(matches):\n",
        "                if not match.item():\n",
        "                    failed_samples.append((data[idx], target[idx].item(), pred[idx].item()))\n",
        "                    #grad_cam = GradCAM(model, 'layer4')\n",
        "                    #heatmap = grad_cam.generate_heatmap(data[idx].unsqueeze(0), pred[idx].item())\n",
        "                    #grad_cam_samples.append((heatmap, target[idx].item(), pred[idx].item()))\n",
        "\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n"
      ],
      "metadata": {
        "id": "Vjfsn3xdwqwk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " summary(model, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "id": "Z161IjcIw8Qk",
        "outputId": "97e77be3-66b2-4163-eb4c-344e700d6e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
            "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.25\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 53.89\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = StepLR(optimizer, step_size=25, gamma=0.5)\n",
        "\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9)\n",
        "EPOCHS =10\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "UmzDzztdwzEK",
        "outputId": "3b798dd5-5dca-415b-82f9-f56da097423d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=-1172235878400.0 Batch_id=195 Accuracy=14.76%: 100%|██████████| 196/196 [00:45<00:00,  4.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: -1290127156654.8992, Accuracy: 1007/10000 (10.07%)\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=-7.405373540792271e+18 Batch_id=116 Accuracy=10.12%:  60%|█████▉    | 117/196 [00:25<00:17,  4.55it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-22dc78cdfd42>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-edd2e5d3b8fb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprocessed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_misclasses(failed_samples,\"Misclassified Images \")"
      ],
      "metadata": {
        "id": "WNjJn6lk0PF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_misclasses(grad_cam_samples,\"Misclassified GradCAM Images \")"
      ],
      "metadata": {
        "id": "uzAseOOL5Ho6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}